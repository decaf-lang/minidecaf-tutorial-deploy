{"./":{"url":"./","title":"实验简介","keywords":"","body":"MiniDecaf 编译实验 实验概述 MiniDecaf 1 是一个 C 的子集，去掉了如 include/define/多文件/struct 等特性。 这学期的编译实验要求你从头开始实现一个编译器，把 MiniDecaf 代码编译到 RISC-V 汇编。 下面是 MiniDecaf 的快速排序，和 C 是一样的 int qsort(int *a, int l, int r) { int i = l; int j = r; int p = *(a + (l+r)/2); while (i p) j = j - 1; if (i > j) break; int u = *(a+i); *(a+i) = *(a+j); *(a+j) = u; i = i + 1; j = j - 1; } if (i l) qsort(a, l, j); } 如目录所示，MiniDecaf 实验分为六大阶段，由十二个小步骤组成。 每个步骤，你的任务都是把 MiniDecaf 程序编译到 RISC-V 汇编。 每步做完以后，你都有一个完整能运行的编译器。 随着实验一步一步进行，MiniDecaf 语言会从简单变复杂，每步都会增加语言特性。 我们提供一系列的参考实现，包含 Python/Rust/Java/C++ 的。遇到困难你可以参考他们做法、也可以复用他们的代码。 编译器边边角角的情况很多，所以你的实现只要通过我们的测例就视为正确。 实验提交 你需要使用 git 对你的实验做版本维护，然后提交到 git.tsinghua.edu.cn。 大家在网络学堂提交帐号名后，助教给每个人会建立一个私有的仓库，作业提交到那个仓库即可。 关于 git 使用，大家也可以在网上查找资料。 每次除了实验代码，你还需要提交 实验报告，其中包括 指导书里面思考题的回答 声明你参考以及复用了谁的代码 晚交扣分规则 是： 晚交 n 天，则扣除 n/15 的分数，扣完为止。例如，晚交三天，那你得分就要折算 80%。 备注 1. 关于名字由来，往年实验叫 Decaf，所以今年就叫 MiniDecaf 了。不过事实上现在的 MiniDecaf 和原来的 Decaf 没有任何关系。 ↩ "},"docs/log.html":{"url":"docs/log.html","title":"更新日志","keywords":"","body":"更新日志 "},"docs/lab0/env.html":{"url":"docs/lab0/env.html","title":"环境配置","keywords":"","body":"环境配置 必做：RISC-V 的 gcc 和 qemu 我们的编译器只生成 RISC-V 汇编，但是提供预编译的 gcc 和 qemu 模拟器。 gcc 用来把 C 编译到汇编、以及把汇编变成 RISC-V 可执行文件；qemu 用来运行 RISC-V 可执行文件。 不过我们提供的 gcc 和 qemu 只能在 Linux/Mac 下运行，Windows 的同学 可以使用 WSL，或者运行一个虚拟机。 关于 WSL / 虚拟机使用，以及 Linux 基础操作，大家可以自己在网上查找资料。 你的编译器 gcc qemu MiniDecaf 源文件 ------------> RISC-V 汇编 -----> 可执行文件 --------> 输出 这一步的环境配置指南 (Windows 同学）配置好 WSL / 虚拟机 从网络学堂下载 riscv-prebuilt.tar.gz 压缩包并解压（命令是 tar xzf riscv-prebuilt.tar.gz） 安装工具链 cp riscv-prebuilt/* /usr/ -r 在第 3. 步，你可以选择不安装到系统目录下。相应的，你需要设置环境变量： export PATH=$PATH:/path/to/riscv-prebuilt/bin，把 /path/to 替换为你的解压目录 执行下面命令测试你 gcc 和 qemu 是否成功安装 1 创建 test.c 文件，其中写入如下内容 #include int main() { printf(\"Hello world!\\n\"); } 编译 test.c 文件，gcc 应该输出一个可执行文件 a.out。但 a.out 是 RISC-V 可执行文件，所以我们的 X86 计算机无法运行。 $ riscv64-unknown-elf-gcc test.c $ ls a.out a.out $ ./a.out bash: ./a.out: cannot execute binary file: Exec format error 使用 qemu 执行 a.out $ qemu-riscv64 a.out Hello world! 推荐：参考实现的环境 我们强烈推荐你选择一个参考实现，并且先测试运行（见下一节）一下，为此你需要配置参考实现的环境。 现在已有如下的参考实现，请根据自己的喜好选择一个，git clone 到本地，然后按照它的 README 配置好它的环境。 Python-ANTLR 地址 https://github.com/decaf-lang/minidecaf/tree/md-dzy clone 命令：git clone git@github.com:decaf-lang/minidecaf.git -b md-dzy Rust-lalr1 地址 https://github.com/decaf-lang/minidecaf/tree/mashplant clone 命令：git clone git@github.com:decaf-lang/minidecaf.git -b mashplant Rust-manual 地址 https://github.com/decaf-lang/minidecaf/tree/md-cy clone 命令：git clone git@github.com:decaf-lang/minidecaf.git -b md-cy Java-ANTLR 地址 https://github.com/decaf-lang/minidecaf/tree/md-xxy clone 命令：git clone git@github.com:decaf-lang/minidecaf.git -b md-xxy C++-ANTLR 有两个，第一个： 地址 https://github.com/decaf-lang/minidecaf/tree/md-tsz clone 命令：git clone git@github.com:decaf-lang/minidecaf.git -b md-tsz 第二个： 地址 https://github.com/decaf-lang/minidecaf/tree/md-zj clone 命令：git clone git@github.com:decaf-lang/minidecaf.git -b md-zj C++-manual 地址 https://github.com/decaf-lang/minidecaf/tree/md-zyr clone 命令：git clone git@github.com:decaf-lang/minidecaf.git -b md-zyr 备注 1. 开头的 $ 表示接下来是一条命令，记得运行的时候去掉 $。例如，让你运行 $ echo x，那你最终敲到终端里的是 echo x（然后回车）。如果开头没有 $，那么这一行是上一条命令的输出（除非我们特别说明，这一行是你要输入的内容）。 ↩ "},"docs/lab0/testing.html":{"url":"docs/lab0/testing.html","title":"运行测试样例","keywords":"","body":"运行测试样例 测试相关的文件在 minidecaf-tests 里面，其中 examples/ 是各个步骤的输入输出，测试脚本是 check.sh。 测试的运行步骤 如下 用 git clone 把 minidecaf-tests 和一个参考实现克隆到同一个目录下面。 进入 minidecaf-tests/，修改 check.sh 的 gen_asm，根据你选择的参考代码反注释某条命令 [可选] sudo apt install parallel 安装 parallel 以便并行测试，测试时间可缩短百分之七八十 [可选] 修改 check.sh 里面的 JOBS，控制要运行哪些测试点 运行 ./check.sh 即可。 测试运行的 输出结果 如下，OK 表示通过，FAIL 表示输出不对，ERR 表示编译错误。 $ ./check.sh gcc found qemu found parallel found OK testcases/step1/multi_digit.c OK testcases/step1/newlines.c ...... 其他测试点，太长省略 OK testcases/step12/matmul.c OK testcases/step12/quicksort.c "},"docs/lab0/riscv.html":{"url":"docs/lab0/riscv.html","title":"RISC-V 的工具链使用","keywords":"","body":"RISC-V 相关信息 RISC-V 是一个 RISC 指令集架构，你实现的编译器要编译到 RISC-V 汇编。 指令集文档在这里，我们只需要其中的 \"Unprivileged Spec\"。 RISC-V 工具使用 我们提供预先编译好的 RISC-V 工具，在环境配置中已经叙述了安装和使用方法。 下面汇总一下。 注意，我们虽然是用的工具前缀是 riscv64， 但我们加上参数 -march=rv32g -mabi=ilp32d 以后就能编译到 32 位汇编。 使用时记得加这个参数，否则默认编译到 64 位汇编。 gcc 编译 input.c 到汇编 input.s，最高优化等级 # input.c 的内容 $ cat input.c int main(){return 233;} # 编译到 input.s $ riscv64-unknown-elf-gcc -march=rv32g -mabi=ilp32d -O3 -S test.c # gcc 的编译结果 $ cat input.s .file \"t3.c\" .option nopic .attribute arch, \"rv32i2p0_m2p0_a2p0_f2p0_d2p0\" .attribute unaligned_access, 0 .attribute stack_align, 16 .text .section .text.startup,\"ax\",@progbits .align 2 .globl main .type main, @function main: li a0,233 ret .size main, .-main .ident \"GCC: (SiFive GCC 8.3.0-2020.04.0) 8.3.0\" gcc 编译 input.s 到可执行文件 a.out # input.s 的内容，就是上面汇编输出的简化版本 $ cat input.s .text .globl main main: li a0,233 ret # 编译到 a.out $ riscv64-unknown-elf-gcc -march=rv32g -mabi=ilp32d input.s # 输出结果，能看到是 32 位的 RISC-V 可执行文件 $ file a.out a.out: ELF 32-bit LSB executable, UCB RISC-V, version 1 (SYSV), statically linked, not stripped qemu 运行 a.out，获取返回码 # 运行 a.out $ qemu-riscv32 a.out # $? 是 qemu 的返回码，也就是我们 main 所 return 的那个值 $ echo $? 233 "},"docs/lab1/part0-intro.html":{"url":"docs/lab1/part0-intro.html","title":"摘要","keywords":"","body":"Lab1：整数 这是关于编写minidecaf编译器的第一个步骤。 编写minidecaf编译器是参考了使用Abdulaziz Ghuloum的An Incremental Approach to Compiler Construction和Nora Sandler的Writing a C Compiler作为路线图。这里的minidecaf语言基本上是C语言的一个子集。你通过从编译minidecaf源语言的一个微不足道的子集开始，能够生成RISC-V汇编代码，并能在RISC-V机器（目前是基于QEMU模拟器）上运行/测试你写的编译器生成的最终机器代码。然后你再一步一步地添加新的语言特性。在第一步中，你只是返回常量；在后面的步骤中，你处理加法和减法；以此类推。每一步都小到足以让人感觉到易于管理，而在每一步结束时，你都有一个可以工作的编译器。另外，通过足够详尽的测试程序，你可以随时验证你的编译器在每次更新后是否正常工作。 前言 在你开始之前，你需要决定两件事：用什么语言来写你的编译器，以及如何处理词法分析（lexing）和语法解析（parsing ） 。你可以用任何你喜欢的语言来实现编译器 提示：建议使用具有和sum type和模式匹配（ pattern matching）的语言，比如OCaml、Haskell或Rust。如果你这样做的话，构建和遍历一个AST会变得更加简单。前提是你能接受学习和掌握这些编程语言的所投入的时间与精力。 你还需要决定是自己写语法解析器和词法分析器，还是使用自动解析器和扫描器生成器（例如flex，bison，antlr4）。在整个实验环节中，两种方式都会提供。我们将展示如何手工编写一个词法器（或扫描器）和递归下降解析器。使用解析器生成器可能更容易，缺点是了解底层运行细节和调试bug可能会困难一些。如果能够直接设计实现解析器生成器，那么对编译课上讲的很多原理、算法的理解会更加深入。 注意：设计实现解析器生成器不是基本实验要求。 本阶段我们将编译一个返回单个整数的minidecaf程序。我们还将建立编译器的三个基本阶段（pass）：词法、解析和代码生成。。第一步将有比较大的工作量，即建立了一个编译器的框架，该框架将使以后添加更多语言特性变得容易，对后续实验步骤有较大的帮助， 下面是一个我们要编译的程序 return_2.c int main() { return 2; } 我们将只处理有一个函数 \"main \"的程序，它由一个返回语句组成。唯一不同的是返回的整数的值，我们不会处理十六进制或八进制的整数，只处理十进制。我们不会处理十六进制或八进制的整数，只处理十进制。为了验证你的编译器是否正常工作，你需要编译一个程序，运行它，并检查它的返回代码。 $ YOUR_COMPILER return_2.c # 用例的编译器会把return_2.c编译为 return.s 汇编程序 $ riscv64-unknown-elf-gcc return_2.s -o return_2 # riscv-64汇编器把return.s翻译为return_2执行程序 $ qemu-riscv64 ./return_2 # 用QEMU for riscv-64硬件模拟器运行return_2执行程序 $ echo $? # 检查return_2执行程序的执行结果，应该是 2 2 你的编译器会产生risc-v汇编代码。我们不会自己将汇编文件转化为可执行文件--那是汇编器和链接器的工作（最好有个链接介绍汇编器和连接器）。为了看看这个程序在汇编中的样子，让我们用GCC来编译它。 $ riscv64-unknown-elf-gcc -S -O3 return_2.c $ cat return_2.s .file \"return_2.c\" ...... .globl main .type main, @function main: li a0,2 ret ...... 现在，让我们看看汇编程序本身。我们可以忽略.section、.align等指令，这些汇编原语可参加这里的介绍。--如果你删除它们，你仍然可以生成并运行return_2执行程序。.globl main表示main符号应该对链接器可见，否则它找不到程序的入口点。 最后，我们有了实际的汇编指令。 main: ; label for start of \"main\" function movl $2, %eax ; move constant \"2\" into the a0 register ret ; return from function 这里最重要的一点是，当一个函数返回时，a0寄存器将包含其返回值。main函数的返回值将是程序的退出代码。在上面的汇编片段中，唯一可以改变的是返回值。 注意：每当你在阅读汇编时，请确保你知道它使用的是什么语法! "},"docs/lab1/part1-lex.html":{"url":"docs/lab1/part1-lex.html","title":"词法分析","keywords":"","body":"词法分析 词法分析器（也叫扫描器或标记器）是编译器的一个阶段，它将一个字符串（源代码）分解成一个标记列表（token list）。一个标记（token）是语法解析器（parser）能够理解的最小单位--如果一个程序就像一个段落，那么标记就像一个个单词(许多标记是用空格隔开的独立的单词)。变量名（variable names）、关键字（keywords）、常量（constants）以及像括号（braces）这样的标点符号都是标记的例子。下面是 return_2.c 中所有标记的列表。 int keyword Identifier “main” Open parentheses Close parentheses Open brace return keyword Constant “2” Semicolon Close brace 注意，有些标记有一个值 (例如常量(constant)标记的值是 \"2\")，有些则没有 (如括号和大括号)。 下面是词法分析器（lexer）需要识别的所有标记，以及定义每个标记的正则表达式（regular expression）。 Open brace { Close brace } Open parenthesis \\( Close parenthesis \\) Semicolon ; Int keyword int Return keyword return Identifier [a-zA-Z]\\w* Integer literal [0-9]+ 提示：你也可以直接使用 \"keyword\"这样统一的一个标记类型（token type），而不是为每个关键词使用不同的标记类型。 ☑任务： 写一个lex函数，接受一个文件并返回一个标记列表。它应该适用于minidecaf测试用例中的所有step1中的示例。为了保持简单，我们只对十进制整数进行词法分析。如果你愿意尝试，你也可以扩展你的词法分析器来处理八进制和十六进制整数。 注意：我们不能对负整数进行词法分析。这并不是偶然的--C 语言没有负整数常量。它只是有一个负一元运算符，可以应用于正整数。我们将在下一步添加负一元运算。 "},"docs/lab1/part1-1-task.html":{"url":"docs/lab1/part1-1-task.html","title":"任务","keywords":"","body":"☑任务： 你可以选择编写一个函数，接受一个输入字符串并返回一个标记列表；或者编写一个相关的类，用字符串来构造它，其中包含一些必要的状态，从而可以让一个成员函数每调用一次返回一个标记。 如果你选择使用的是flex这样的语法分析工具，它自动生成的文件可能是一个依赖于很多全局变量的函数，也能做到每调用一次返回一个标记；此外它可能是接受一个输入的文件，而不是输入的字符串，显然如果我们要自己实现的话还是接受字符串更简单一些。其实这些与上面描述的也没有本质的区别。 你编写的类或者函数应该可以正确处理minidecaf测试用例中step1中的所有测例。 注意：根据step1的spec，我们不能处理return负整数的程序。这并不是偶然的--C语言没有负整数常量，它只是有一个可以应用于正整数的负号运算符，这是下一步的工作了。 "},"docs/lab1/part2-parse.html":{"url":"docs/lab1/part2-parse.html","title":"语法分析","keywords":"","body":" 注意：我们不能对负整数进行词法分析。这并不是偶然的--C 语言没有负整数常量。它只是有一个负一元运算符，可以应用于正整数。我们将在下一步添加负一元运算。 语法解析 下一步是将我们的标记列表转化为抽象的语法树（Abstract Syntax Tree，简称AST）。AST是表示程序结构的一种方式。在大多数编程语言中，像条件和函数声明这样的语言结构是由更简单的结构组成的，比如变量和常量。AST捕捉到了这种关系；AST的根将是整个程序，而每个节点将有子节点代表它的组成部分。让我们来看一个小例子。 if (a 这段代码是一个if语句，所以我们将AST的根标记为 \"if statement\"。它有三个子节点： 表达式：condition (a ) 语句列表：if body (c = 2; return c;) 语句列表：else body (c = 3;) 这些节点都可以进一步分解。例如，condition (a )表达式是一个有两个操作数（operand ）子节点的\"二元操作的AST节点： first operand (variable a) second operand (variable b) 一个赋值语句（如c=2;）也有两个子节点：被更新的变量（c）和赋值给它的表达式（2）。 另一方面，if body是语句列表，它可以有任意数量的子节点--每个语句都是一个子节点。在本例中，它有两个子节点，因为有两条语句。这些子节点是有序的--c=2;排在return c;之前，因为在源代码中就是这样按序排列的。 下面是这段代码的完整AST： if statement condition: binary operation ( operand 1: variable a operand 2: variable b if body: statement list statement 1: assignment variable: c right-hand side: constant 2 statement 2: return return value: variable c else body: statement list statement 1: assignment variable: c right-hand side: constant 3 而这里是构造这个AST的伪代码： //create if condition cond = BinaryOp(op='>', operand_1=Var(a), operand_2=Var(b)) //create if body assign = Assignment(var=Var(c), rhs=Const(2)) return = Return(val=Var(c)) if_body = [assign, return] //create else body assign_else = Assignment(var=Var(c), rhs=Const(3)) else_body = [assign_else] //construct if statement if = If(condition=cond, body=if_body, else=else_body) 不过现在我们不需要担心条件（conditionals）、变量赋值（variable assignments）或二进制操作符（binary operators）。现在，我们需要支持的AST节点只有程序（programs）、函数声明（function declarations）、语句（statements）和表达式（expressions）。下面是我们对return_2.c给出的AST节点的定义： program = Program(function_declaration) function_declaration = Function(string, statement) //string is the function name statement = Return(exp) exp = Constant(int) 现在，一个程序由一个函数main组成。在后面的步骤中，我们将把一个程序定义为一个函数列表。一个函数有一个名称（name）和一个函数体（body）。以后，一个函数还会有一个参数列表（list of arguments）。在实际的编译器中，我们还需要存储函数的返回类型（return type），但现在我们只有整数类型。函数体中只包含一条单一的语句（后续会扩展为语句列表）。语句的类型只有一种：返回语句（return statement）。以后我们会增加其他类型的语句，比如条件（conditionals）和变量声明（variable declarations）。一个返回语句有一个子语句，即表达式--这就是被返回的值。现在一个表达式只能是一个整数常量。以后我们会让表达式包含算术运算，这将使我们能够解析像return 2+2;这样的语句。 当我们添加新的语言结构时，我们会更新AST节点的定义。例如，我们最终会添加一种新的语句类型：变量赋值。当我们这样做的时候，我们会在我们的statement定义中添加一个新的形式。 statement = Return(exp) | Assign(variable, exp) 这里是return_2.c的AST图。 最后，我们需要一个形式化的语法，它定义了一系列标记如何组合成语言构造。我们将基于Backus-Naur Form来定义： ::= ::= \"int\" \"(\" \")\" \"{\" \"}\" ::= \"return\" \";\" ::= 上面的每一行都是一个产生式（production ），定义了如何从一种形式语言（BNF）的构造和标记来建立另外一个语言（minidecaf）的构造。每一个出现在产生式左侧的符号（即、、）都是一个非终结符（non-terminal symbol）。个别标记（keywords、id、punctuation等）是终结符（terminal symbols）。请注意，虽然这个语法告诉我们什么样的标记序列构成了一个有效的minidecaf程序，但它*没有告诉我们到底如何将这个程序转化为AST--例如，在AST中没有对应Constant节点的产生式。我们可以重写我们的语法，让常量有一个产生式，但这不是必须的。 现在的语法非常简单，每个非终结符只有一条产生式。在后续试验中，一些非终结符将有多个产生式。例如，如果我们增加了对变量声明的支持，我们就可以有以下的产生式。 ::= \"return\" \";\" | \"int\" \"=\" \";\" "},"docs/lab1/part2-1-rdp.html":{"url":"docs/lab1/part2-1-rdp.html","title":"递归下降分析","keywords":"","body":"递归下降解析 为了将一个标记列表转化为AST，我们将使用一种叫做递归下降解析的技术。我们将定义一个函数来解析语法中的每个非终结符，并返回一个相应的AST节点。解析符号S的函数应该从列表的开头删除标记，直到它到达S的有效派生。如果在它完成解析之前，碰到了一个不在S的产生式中的标记，它应该失败。如果 S 的产生式规则包含其他非终结符，它应该调用其他函数来解析它们。 下面是解析语句的伪代码。 def parse_statement(tokens): tok = tokens.next() if tok.type != \"RETURN_KEYWORD\": fail() tok = tokens.next() if tok.type != \"INT\" fail() exp = parse_exp(tokens) //parse_exp will pop off more tokens statement = Return(exp) tok = tokens.next() if tok.type != \"SEMICOLON\": fail() return statement 后面可以发现，产生式是递归的（例如一个算术表达式可以包含其他表达式），这意味着解析函数也将是递归的--因此这种技术被称为递归下降解析。 "},"docs/lab1/part2-2-task.html":{"url":"docs/lab1/part2-2-task.html","title":"任务","keywords":"","body":"☑任务： 编写一个parse函数，接受一个标记列表，并返回一个AST，根节点（root node）是Program节点。该函数应该为所有有效的step1测试用例建立正确的AST。如果你愿意，你也可以让你的解析器在遇到超过INT_MAX（整数最大值）的整数常量时优雅地失败并指出解析失败的原因。 有很多方法可以在代码中表示AST--每种类型的节点可以是它自己的类或它自己的数据类型，这取决于你用什么语言来编写编译器。例如，以下是你如何将AST节点定义为数据类型伪代码： type exp = Const(int) type statement = Return(exp) type fun_decl = Fun(string, statement) type prog = Prog(fun_decl) "},"docs/lab1/part3-ir.html":{"url":"docs/lab1/part3-ir.html","title":"中间码","keywords":"","body":"中间代码生成 IR IR也是表示程序结构的一种方式，一般来说IR比AST更加接近汇编，但是仍然保存了一些程序中的高级信息，因此比汇编更加容易优化。 IR有很多种类，包括三地址码(Three Address Code, TAC)，静态单赋值形式(Static Single Assignment Form, SSA)，基于栈的IR，等等。如果你感兴趣的话可以自行查阅了解，这里不做要求。 我们这里使用基于栈的IR。这种IR的最大特点是中间代码生成和汇编代码生成(不追求性能的话)非常容易编写，但是一般实际的编译器都不会使用它，因为它并不适合进行优化，这样其实也就失去了IR存在的根本意义之一了。 类似Java Bytecode这样的，虽然也可以看做是基于栈的IR，但是实际的Java虚拟机中都会先把它转化成其它容易优化的形式，所以它的意义仅仅是便于生成和传输，不会用于汇编代码生成。 尽管如此，我们这个教学用的编译器还是选择使用基于栈的IR，主要目的是能够体现IR这个结构在实际的编译器中的地位，尽量让大家体会感受编译器的工作流程，只是限于课程的工作量的限制还是没法和实际的编译器做到真正的一致。 基于栈的IR顾名思义维护一个运算栈，它最主要的特点在于它的运算指令，例如加法和减法指令这些，是没有操作数的。所有的运算指令的语义都是从这个运算栈的顶部弹出操作数，进行运算后再把结果压回栈中。这里不能完全理解也没有关系，我们之后每加入新的指令时都会介绍其功能和特点。 本阶段用到的指令 现在唯一可能的语句是return一个常数，所以IR中完全可以只设计一条指令，也就是return一个常数，这个常数也作为指令的一部分。但是我们不推荐这样的设计，因为这样完全无法兼容后面的新语法，之后可以return一个变量之后，这条return常数的指令事实上是完全用不上了，所以反而总工作量还变大了。 我们的建议是设计两条指令： PUSH指令，指令中还包含一个常数，语义是将这个常数压入栈中 RET指令，语义是将栈顶的值弹出，将这个值作为返回值结束程序 对于一条return常数的指令，就依次生成这两条指令即可。 "},"docs/lab1/part3-1-task.html":{"url":"docs/lab1/part3-1-task.html","title":"任务","keywords":"","body":"任务 编写一个函数，将AST中的main函数转化为一段指令序列。因为本阶段程序中只可能有一个函数，所以其实在IR的层面也不需要有函数的概念，整个程序就是一段指令序列。 "},"docs/lab1/part4-codegen.html":{"url":"docs/lab1/part4-codegen.html","title":"代码生成","keywords":"","body":"汇编代码生成 我们选择的目标平台是RISC-V 64，我们可以先看看常见的编译器生成的汇编代码是什么样的： $ riscv64-linux-gnu-gcc return2.c -S -O3 $ cat return2.s .file \"return2.c\" .option nopic .text .section .text.startup,\"ax\",@progbits .align 1 .globl main .type main, @function main: li a0,2 ret .size main, .-main .ident \"GCC: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\" 其实这里有很多多余的信息，你可以自己尝试一下，只留下最关键的一些表示main函数的信息就可以经由汇编器和链接器生成正确的程序： .globl main main: li a0,2 ret 这里做的事情倒是很直接，就是直接return一个常数了，不过跟我们上面描述的两条指令做到事情还是不太一样。为了能够模拟我们描述的PUSH和RET的操作，还是有必要了解一下RISC-V指令集和相关的调用约定的知识，不过为了减小大家的工作量，这个阶段我们不要求你们去自行查阅，而是把必要的知识都列出来： 我们假定整数都是64位的，因此运算栈中的一个元素占据8字节 我们可以用sp寄存器来表示栈，sp的值就是栈顶，但是这个栈是向地址低的地方生长的，所以如果sp的值减少8，就意味着栈增长了一个元素 我们可以用t开头的寄存器来进行一些临时的数据存储和运算 最终函数的返回值需要保存到a0寄存器中 li指令用来加载一个常数到寄存器中，sd指令用来把一个寄存器中的值保存到一个内存地址，ld指令用来把一个内存地址中的值读入到一个寄存器，ret用来执行函数返回 所以，对于一条PUSH指令，可以生成这样的代码： li t0, # 用t0临时存储这个常数 sd t0, -8(sp) # 把t0中的值保存在栈顶后的一个元素的位置 add sp, sp, -8 # 栈增长一个元素，这一条和上面一条合起来就是压入一个元素 对于一条RET指令，可以生成这样的代码： ld a0, 0(sp) # 从栈顶读出值到表示返回值的寄存器 add sp, sp, 8 # 栈减小一个元素，这一条和上面一条合起来就是弹出一个元素，并把值赋给a0 ret # 函数返回 最终你为return2.c生成的整个汇编程序可以是这个样子的： .globl main main: li t0, 2 sd t0, -8(sp) add sp, sp, -8 ld a0, 0(sp) add sp, sp, 8 ret "},"docs/lab1/part4-1-task.html":{"url":"docs/lab1/part4-1-task.html","title":"任务","keywords":"","body":"☑任务： 写一个generate函数，接受一个AST并生成汇编。它可以以字符串的形式在屏幕上显示汇编代码，也可以直接把汇编代码写到文件中。它应该为所有step1测试用例生成正确的汇编码。 ☑ 任务：写一个pretty-print funcion，它接收一个AST并以可读的方式打印出来。 写一个pretty-print的函数，接受一个AST并以可读的方式打印出来。 (可选) 漂亮的打印 你可能需要一个实用函数来打印出你的AST，以帮助调试。你可以现在就写，或者等到你需要的时候再写。下面是对return_2.c的AST输出例子： FUN INT main: params: () body: RETURN Int 这个例子包含了一些AST不需要的信息，比如返回类型和函数参数列表。 ☑任务： 编写一个接受C源文件并输出可执行文件的程序（可以是一个包含调用你写的编译器和GCC的shell脚本）。该程序应该 读取minidecaf源文件 进行词法分析 进行语法解析 生成汇编码 把汇编码写入到一个文件 调用GCC命令，将生成的汇编码转换为可执行文件。在下面命令中，\"assembly.s \"是汇编文件的名称，\"out \"是你想生成的可执行文件的名称。 riscv64-unknown-elf-gcc assembly.s -o out (可选) 删除汇编文件。 "},"docs/lab1/summary.html":{"url":"docs/lab1/summary.html","title":"小结","keywords":"","body":"下一步 在下一步中，我们将增加三个单数运算符。-、~和！。 参考 An Incremental Approach to Compiler Construction Writing a C Compiler "},"docs/lab1alt/part1.html":{"url":"docs/lab1alt/part1.html","title":"第一部分：从零开始的 lexer、parser 以及汇编生成","keywords":"","body":"实验指导 step1：词法分析、语法分析、目标代码生成 第一个步骤中，MiniDecaf 语言的程序就只有 main 函数，其中只有一条语句，是一条 return 语句，并且只返回一个整数（非负常量），如 int main() { return 233; }。 第一个步骤，我们的任务是把这样的程序翻译到汇编代码。 不过，比起完成这个任务，更重要的是你能 知道编译器包含哪些阶段，并且搭建起后续开发的框架 了解基本概念、包括 词法分析、语法分析、语法树、栈式机模型、中间表示 学会开发中使用的工具和设计模式，包括 ANTLR 工具 和 Visitor 模式 词法分析 读内容 *词法分析* MiniDecaf 源文件 --------> 字节流 ----------> Tokens --> ...... --> RISC-V 汇编 词法分析（lexical analysis） 是我们编译器的第一个阶段，实现词法分析的代码称为 lexer ， 也有人叫 scanner 或者 tokenizer。 它的输入 是源程序的字节流 如 \"\\x69\\x6e\\x74\\x20\\x6d\\x61\\x69\\x6e\\x28\\x29\\x7b\\x72\\x65\\x74\\x75\\x72\\x6e\\x20\\x30\\x3b\\x7d\"。 上面的其实就是 \"int main(){return 0;}\"。 它的输出 是一系列 词（token） 组成的流（token stream）1 上面的输入，经过 lexer 以后输出如 [关键字(int)，空白、标识符(main)，左括号，右括号，左花括号，关键字(return)，空白、整数(0)，分号，右花括号]。 如果没有词法分析，编译器看到源代码中的一个字符 '0'，都不知道它是一个整数的一部分、还是一个标识符的一部分，那就没法继续编译了。 为了让 lexer 完成把字节流变成 token 流的工作，我们需要告诉它 有哪几种 token 如上，我们有：关键字，标识符，整数，空白，分号，左右括号花括号这几种 token token 种类 和 token 是不一样的，例如 Integer(0) 和 Integer(222) 不是一个 token，但都是一种 token：整数 token。 对于每种 token，它能由哪些字节串构成 例如，“整数 token” 的字节串一定是 “包含一个或多个 '0' 到 '9' 之间的字节串” 词法分析的正经算法会在理论课里讲解，但我们可以用暴力算法实现一个 lexer。 例如我们实现了一个 minilexer（代码）当中， 用一个包含所有 token 种类的列表告诉 lexer 有哪几种 token（上面第 1. 点）， 对每种 token 用正则表达式描述它能被那些字节串构成（上面第 2. 点）。 细化到代码，Lexer 的构造函数的参数就包含了所有 token 种类。 例如其中的 TokenType(\"Integer\", f\"{digitChar}+\", ...) 就定义了 Integer 这种 token， 并且要求每个 Integer token 的字符串要能匹配正则表达式 [0-9]+，和上面第 2. 点一样。 你可尝试运行 minilexer，运行结果如下（我们忽略了空白） $ python3 minilexer.py Int int Ident main Lparen ( Rparen ) Lbrace { Return return Integer 123 Semicolon ; Rbrace } 本质上，token 是上下文无关语法的终结符，词法分析就是把一个字节串转换成上下文无关语法的 终结符串 的过程。 不过 token 比单纯的终结符多一个属性，就是它的字符串（如 Ident(main) 的 main），你可以说 token 是有标注的终结符。 语法分析 词法分析 *语法分析* 字节流 ----------> Tokens ----------> 语法树 --> ...... --> RISC-V 汇编 语法分析（syntax analysis） 是紧接着词法分析的第二个阶段，实现语法分析的代码称为 parser 。 它的输入 是 token 流 就是 lexer 的输出，例子上面有 如果输入没有语法错误，那么 它的输出 是一颗 语法树（syntax tree） 比如上面的程序的语法树类似 编译原理的语法树就类似自动机的 语法分析树，不同的是语法树不必表示出实际语法中的全部细节。 例如上图中，几个表示括号的结点在语法树中是可以省略的。 语法分析在词法分析的基础上，又把程序的语法结构展现出来。 有了语法分析，我们才知道了一个 Integer(0) token 到底是 return 的参数、if 的条件还是参与二元运算。 为了完成语法分析，肯定要描述程序语言的语法，我们使用 上下文无关语法 描述 MiniDecaf。 就这一步来说，MiniDecaf 的语法很简单，产生式大致如下，起始符号是 prog。 prog : func func : ty Ident Lparen Rparen Lbrace stmt Rbrace ty : Int stmt : Return expr Semicolon expr : Integer 一些记号的区别： 形式语言与自动机课上，我们用大写字母表示非终结符，小写字母表示终结符。 这里正好相反，大写字母开头的是终结符，小写字母开头的是非终结符。 并且我们用 : 而不是 -> 隔开产生式左右两边。 同样的，语法分析的正经算法会在课上讲到。 但我们实现了一个暴力算法 miniparser（代码）。 这个暴力算法不是通用的算法，但它足以解析上述语法。 你可尝试运行，运行结果如下（下面输出就是语法树的先序遍历） $ python3 miniparser.py prog(func(ty(Int), Ident(main), Lparen, Rparen, Lbrace, stmt(Return, expr(Integer(123)), Semicolon), Rbrace)) 前面提到，语法树可以不像语法分析树那样严格。 如果语法树里面抽象掉了程序的部分语法结构，仅保留底下的逻辑结构，那样的语法树可以称为 抽象语法树（AST, abstract syntax tree）；而和语法完全对应的树称为 具体语法树。 当然，AST 和语法树的概念没有清楚的界限，它们也常常混用，不必扣概念字眼。 上面 miniparser 的输出就是一颗具体语法树，而它的抽象语法树可能长成下面这样（取决于设计） $ python3 miniparser-ast.py # 假设有个好心人写了 miniparser-ast.py Prog(funcs=[ Func(name=\"main\", type=(\"int\", []), body=[ ReturnStmt(value=Integer(123)) ]) ]) 目标代码生成 词法分析 语法分析 *目标代码生成* 字节流 ----------> Tokens ----------> 语法树 -----------> RISC-V 汇编 生成 AST 以后，我们就能够生成汇编了，所以 目标代码生成（target code emission） 是第三也是最后一个步骤，这里目标代码就指 RISC-V 汇编。 它的输入 是一颗 AST 它的输出 是汇编代码 这一步中，为了生成代码，我们只需要 遍历 AST，找到 return 语句对应的 stmt 结点，然后取得 return 的值, 设为 X 2 打印一个返回 X 的汇编程序 针对第 1. 点，我们使用一个 Visitor 模式来完成 AST 的遍历。 同样，我们有一个 minivisitor（代码）作为这个阶段的例子。 Visitor 模式比简单的递归函数更强大，用它可以让以后的步骤更方便。 Visitor 模式速成请看 这里 针对第 2. 点，我们用 (RISC-V) gcc 编译一个 int main(){return 233;} 就能知道这个汇编程序什么样。 gcc 的输出可以简化，去掉一些不必要的汇编指令以后，这个汇编程序长成下面这样。 编译方法请看 工具链使用。 汇编代码中，li 加载常数 X 到 a0 寄存器。RISC-V 约定 a0 保存返回值，之后 ret 就完成了 return X 的工作。 .text .globl main main: li a0,X ret 运行 minivisitor，输出就是模板中的 X 被替换为了一个具体整数 $ python minivisitor.py .text .globl main main: li a0,123 ret 至此，我们的编译器就完成了，它由三个阶段构成：词法分析、语法分析、目标代码生成。 每个阶段都有自己的任务，并且阶段和阶段之间的接口很明确：字节流、token 流、AST、汇编代码。 任务 在不同输入上，运行 minilexer, miniparser 和 minivisitor。 浏览它们的代码（不用完全看懂） 思考题 以下思考题六选四，在实验报告中回答。 minilexer 是如何使得 int 被分析成一个关键字而非一个标识符的？ 修改 minilexer 的输入（lexer.setInput 的参数），使得 lex 报错，给出一个简短的例子。 miniparser 的算法，只有当语法满足什么条件时才能使用？ 修改 minilexer 的输入，使得 lex 不报错但 parser 报错，给出一个简短的例子。 一种暴力算法是，只做 lex，然后在 token 流里面寻找连续的 Return，Integer 和 Semicolon，找到以后取得 Integer 的常量 a，然后类似上面目标代码生成。这个暴力算法有什么问题？ 除了我们的暴力 miniparser，形式语言与自动机课中也描述了一种算法，可以用来计算语法分析树。请问它是什么算法，时间复杂度是多少？ 总结 本节引入了概念 Lexer Token Parser 抽象语法树 目标代码生成 Visitor 备注 1. 之所以说“流”而不是“列表”，是因为不一定 lexer 一下就把所有的 token 都拿出来，还可以按照后续阶段的需要按需返回 token。 ↩ 2. 当然，就第一个步骤来说，你直接找到 Integer 节点也可以 ↩ "},"docs/lab1alt/part2.html":{"url":"docs/lab1alt/part2.html","title":"第二部分：词法语法分析工具","keywords":"","body":"实验指导 step1：词法语法分析工具 第一部分中，我们已经自己从零开始暴力实现了一个编译器，接下来我们就来改进它。 第一个方向是： 使用工具完成词法语法分析，而不是自己手写 。 本节内容非必做。 如果你不做，那么你要自己实现 lexer/parser。 概述 从 minilexer/miniparser 的代码可以看出，lexer 和 parser 包含两部分： 被分析的词法/语法的描述。例如 minilexer 的那个 TokenType 列表，以及 miniparser 的 rules 字符串； lexer 和 parser 的驱动代码。例如 lex 和 parse 函数。 使用工具，我们只需要完成第一步，描述被分析的词法或者语法。 然后工具从我们的描述，自动生成 lexer 或者 parser。 所以这类工具被称为 lexer/parser generator，例子有：C 的 lex/yacc、往届使用的 JFlex / Jacc、mashplant 助教自己写的 lalr1。 对有兴趣的同学：除了这类工具以外，还有一类工具称为 parser combinator，多在函数式语言中使用。 最有名的如 Haskell 的 parsec、scala 的 fastparse，rust 的 nom。课程不涉及其中内容。 ANTLR ANTLR 是一个比较易用的 parser generator，速成文档在这里。 任务 用工具描述 step1 的 MiniDecaf 词法语法，并参考第一部分的描述，生成汇编。 "},"docs/lab1alt/part3.html":{"url":"docs/lab1alt/part3.html","title":"第三部分：使用中间码","keywords":"","body":"实验指导 step1：使用中间码 我们继续改进上一步我们得到的编译器，这次要做的是： 使用中间码让编译器更模块化。 栈机器和中间表示 …… 什么是，为什么 …… …… 手动翻译 IR …… …… Visitor 生成 IR …… …… IR 生成汇编代码 …… 任务 改进你上一步的代码，先生成 IR，再从 IR 生成汇编。 思考题 ANTLR 栈机器 总结 "},"docs/lab1alt/antlr.html":{"url":"docs/lab1alt/antlr.html","title":"ANTLR 使用","keywords":"","body":"ANTLR 使用——以表达式语法为例 使用 ANTLR 工具，我们只需要写出词法和语法分析的 规范（specification）， 然后它会帮我们生成 lexer 和 parser 乃至 visitor，非常方便。 我们用一个简单的表达式语法 1 来介绍 ANTLR，表达式由一系列整数通过加减乘除以及括号构成，例如 (1+3)*4-3-3。 对于 ANTLR，词法和语法分析的规范都写在 .g4 2 文件中，例如我们的表达式的规范是文法: ExprLex.g4和语法: Expr.g4。 无论是词法规范还是语法规范，它们的规范文件结构是一样的，如下。 规范文件中，// 表示注释，规范是大小写敏感的，字符串常量用单引号括起。 开头声明 规范名，需要和文件名一致： ```antlr4 // [ExprLex.g4] 词法规范，用 lexer grammar 标识，行尾有分号。 lexer grammar ExprLex; // [Expr.g4] 语法规范，用 grammar 标识，行尾有分号。 grammar Expr; 2. 然后可能有一些 **规范自身的设置**，见后面 “语法规范” 3. 然后是 **一系列规则**，规则类似上下文无关语法的产生式。 每条规则包含左右两边，用冒号隔开， *左边* 是一个符号，表示 *右边* 可以规约到 *左边* 的符号。 符号分为 **终结符** 和 **非终结符** ，终结符用大写字母打头，非终结符用小写字母。 类似产生式，如果多条规则的左边相同，它们可以合并写在一起，它们的右手边用竖线隔开。 ```antlr4 // [ExprLex.g4] 词法规则，规则末尾有分号。 Integer: [0-9]+; // [Expr.g4] 语法规则，规则末尾有分号 atom : '(' expr ')' // 一个括号括起来的表达式，它可以规约到 atom | Integer // 整数 token 可以规约到 atom ; 词法规范 词法规范描述了 lexer 应该怎么生成，显然词法规范中规则的左边只能是终结符。 除了上面所说的，词法规范还有一点是：规则的右手边是一个正则表达式。 详细用法在这里，一些常见用法如下： // 1. 为了匹配字符串常量，用单引号把它括起来 Lparen: '('; // 2. [0-9] 匹配 (char)'0' 到 (char)'9' 之间任何一个字符，类似其他 regex 的 \\d 或者 [[:digit:]] // 3. 加号 + 表示它前面的片段可以匹配一次或多次，类似有 * 的零次或多次，? 的零次或一次。 // 它们都是贪婪的，会匹配尽量多的次数。和其他 regex 一样，片段可以用 ( ) 分组。 Integer: [0-9]+; // 4. fragment 表示 WhitespaceChar 本身不是一个符号，它只是一个 regex 的片段，lexer 不会产生它的 token。 // 它和 minilexer 中的 whitespaceChar 是一样的。 // 5. [ \\t\\n\\r] 匹配一个空格 (ascii 码 0x20)，或者一个制表符 (0x9)，或者一个换行符 (0xa) 或者一个回车 (0xd) fragment WhitespaceChar: [ \\t\\n\\r]; // 6. Whitespace 匹配输入中的空白。类似 minilexer，\"-> skip\" 表示忽略此终结符，也就是匹配以后不产生对应的 token。 Whitespace: WhitespaceChar+ -> skip; 语法规范 语法规范描述了 parser 应该怎么生成。除了上面说的，还需注意： parser 依赖于 lexer，所以语法规范中需要 导入词法规范// 导入词法规范 import ExprLex; 其实 ANTLR 不要求你分开 lexer 和 parser，你可以直接把 import 语句换成 ExprLex 里面的所有规则， 效果是一样的。 但分开 lexer 和 parser 更干净，并且也方便 lexer 复用。 各种语言虽然语法差别很大，词法（空白、整数、标识符、标点符号等）却没太大差别。 parser 规则的右手边除了符号以外，还可以有 字符串常量。 如果它能被规约到词法规范里某个符号，那它就等价于那个符号； 否则 ANTLR 内部会生成一个临时终结符 T__xxx，它的规则的右边是那个字符串常量。 mulOp : '*' | '/' ; // 等价于 mulOp : Mul | Div ; 你可以手动给 规则命名。 在生成的 AST 里，atom 对应的结点会被分为两类：atomParen 和 atomInteger， 它们拥有的字段不同，也对应不同的 visit 函数。 atom : '(' expr ')' # atomParen | Integer # atomInteger ; 规则其实是用 EBNF (extended Barkus-Naur form) 记号书写的，EBNF 也是描述上下文无关语法的一种方式。 相对普通的上下文无关语法记号，EBNF 允许你在规则内部使用 | 描述选择、* 或 ? 或 + 描述重复，(和) 分组 3。 例如下面的用法： ```antlr4 add // 1. 使用括号分组，分组内部使用 | 描述选择 // 2. 和 EBNF 无关，但 op 是给这个符号的命名，然后 add 的 AST 结点会有一个 op 字段。 : add op=(Add|Sub) mul | mul ; mul // 3. 使用 描述零次或多次的重复。+ 和 ? 类似。 : atom (mul atom) ; 关于 EBNF，再举一个例子：描述零个或多个用逗号隔开的 `expr` 列表，下面两种写法是等价的，但 EBNF 记号更简短。 ```antlr4 // 传统写法 exprList : # emptyExprList | exprList2 # nonemptyExprList ; exprList2 : expr | expr ',' exprList2 ; // EBNF 写法 exprList : (expr (',' expr)*)? ; 运行 ANTLR 安装 ANTLR，设置 CLASSPATH 环境变量，配置 antlr4 和 grun 的 alias 后，运行以下命令 4： $ antlr4 Expr.g4 # 会自动拉取 import 的 ExprLex.g4 $ ls ExprLexer.java ExprParser.java # 默认生成 Java 的 lexer 和 parser，其他文件不用管 ExprLexer.java ExprParser.java $ javac *.java $ echo \"(1+3)*4-3-3\" > input # 输入文件内容是 (1+3)*4-3-3 $ grun Expr expr -gui input # 输出如下图 你可以尝试把最后一步的 -gui 换成 -tokens、-tree 看看。 接下来，我们给出示例代码，叙述如何使用生成的 lexer 和 parser。 Main.java 是 Java 的示例代码。做完上面步骤后，运行 Main： $ java Main main.py 是 Python 的示例代码。为了运行它，除了安装 ANTLR 你还需要安装 Python 的 ANTLR API，见这里。运行方法如下 $ antlr4 Expr.g4 -Dlanguage=Python3 $ ls ExprParser.py ExprLexer.py # 生成了 Python 的 lexer 和 parser ExprLexer.py ExprParser.py $ python3 main.py (expr (add (add (add (mul (atom ( (expr (add (add (mul (atom 1))) + (mul (atom 3)))) )) (mulOp *) (atom 4))) - (mul (atom 3))) - (mul (atom 3)))) Visitor 的使用 ANTLR 默认生成 listener，它允许你在遍历 AST 过程进入结点和离开结点的时候运行一些代码，但我们不用 listener，我们使用 visitor。 首先用参数 -visitor 告诉 ANTLR 生成 visitor 代码。 $ antlr4 Expr.g4 -visitor visitor 代码在 ExprVisitor.java 和 ExprBaseVisitor.java 中。 前者定义接口，后者是默认实现：只遍历、不做其他事。 public class ExprBaseVisitor extends AbstractParseTreeVisitor implements ExprVisitor { @Override public T visitExpr(ExprParser.ExprContext ctx) { return visitChildren(ctx); } // ... } 从上可以看出，ANTLR 的 visitor 和我们的基本一致： visit 函数返回值的类型是 T 他所谓 context 就是 AST 的结点，每个 context 也有一个 accept 函数接受 visitor 但他的 visitor 还自带一个方法 visitChildren：遍历所有子结点。返回最后一个子结点的返回值。 ANTLR 生成的 python visitor 也差不多 $ antlr4 Expr.g4 -visitor -Dlanguage=Python3 visitor 在 ExprVisitor.py 里。 # ExprVisitor.py class ExprVisitor(ParseTreeVisitor): def visitExpr(self, ctx:ExprParser.ExprContext): return self.visitChildren(ctx) # ... MainEval.java 和 maineval.py 通过表达式求值展现了 visitor 的用法，如上编译后如下运行即可。 输出的 10 就等于 (1+3)*4-3-3。 $ python3 mainvisitor.py 常见问题 javac 报错一堆 cannot find symbol 没有设置 CLASSPATH grun 报错 Can't load Expr as lexer or parser 你 antlr4 以后没有编译 java 文件 我的输入是 1+2 ((( 它竟然不报错 ANTLR 不强制消耗整个输入，所以 parser 做完 1+2 就停了。 可以把 expr: add; 改成 expr: add EOF; antlr4 报错 error(31): ANTLR cannot generate python3 code as of version 4.8 -Dlanguage=Python3 的 P 要大写 备注 1. step1 的 MiniDecaf 语法太简单，不能体现很多 ANTLR 的特性。 ↩ 2. g 是 grammar，4 是 ANTLR 的版本号 4。 ↩ 3. EBNF 本身又有很多记号，有的使用 { ... } 表示重复。我们描述的是 ANTLR 的 EBNF 记号。 ↩ 4. 命令从 https://www.antlr.org/ 中 Samples 的内容修改而来 ↩ "},"docs/lab1alt/visitor.html":{"url":"docs/lab1alt/visitor.html","title":"Visitor 模式","keywords":"","body":"Visitor 模式速成 编译器的构造中会使用到很多设计模式，Visitor 模式就是常见的一种。 基础的设计模式都在 OOP 课程中覆盖，这里重提一下 Visitor 模式，顺带介绍一些参考代码用到的 python 技巧。 我们知道，编译器里有很多的树状结构。 最典型的就是，源程序通过上下文无关文法解析后，得到的语法分析树。 Visitor 模式的目的，就是遍历这些树状结构，本质就是一个 DFS 遍历。 下面通过一个例子说明 Visitor 模式。 表达式语法、语法树定义 我们有一个很简单的表达式文法，终结符包括整数和加减乘除模操作符，起始符号是 expr，大致如下 expr -> int | binary int -> Integer binary -> expr '+' expr | expr '-' expr | expr '*' expr | expr '/' expr | expr '%' expr 这个文法有二义性，同样的字符串可能有多个语法分析树。 不过解析字符串、生成语法分析树不是 Visitor 模式的工作。 Visitor 模式只考虑某个确定的语法分析树。 如下面是 20-13*3 的一颗语法分析树 我们在代码里这样定义这个语法分析树（python 3.6）： class Node: pass class IntNode(Node): def __init__(self, v:int): # 类型标注是给人看的，python 不检查 self.v = v def __str__(self): return f\"({self.v})\" # f-string 特性 class BinopNode(Node): _legalOps = { *\"+-*/%\" } # 使用 unpacking operator，等价于 set('+', '-', '*', '/', '%') def __init__(self, op:str, lc:Node, rc:Node): assert op in BinopNode._legalOps self.op, self.lc, self.rc = op, lc, rc def __str__(self): return f\"({self.lc} {self.op} {self.rc})\" # 我们通过某种手段，得到了这么一个语法分析树 expr1 = BinopNode('*', BinopNode('-', IntNode(20), IntNode(13)), IntNode(3)) print(expr1) # (((20) - (13)) * (3)) 我们忽略了 Expr，不过显然这无伤大雅。 表达式求值 显然，每个语法分析树都对应一个（加好括号）的表达式，比如上面的树就对应 (20-13)*3。 那么我们考虑一个问题：如何对这个表达式求值？ 当然，我们可以让 python 帮我们做 print(eval(str(expr1), {}, {}))， 不过我们下面会用 Visitor 模式实现表达式求值。 写 Visitor 之前，我们看自己实现表达式求值的最简单的方法，一个递归遍历： def dfs(node:Node): if isinstance(node, IntNode): return node.v if isinstance(node, BinopNode): lhs = dfs(node.lc) rhs = dfs(node.rc) if node.op == \"+\": return lhs + rhs if node.op == \"-\": return lhs - rhs if node.op == \"*\": return lhs * rhs if node.op == \"/\": return lhs / rhs if node.op == \"%\": return lhs % rhs print(dfs(expr1)) # 21 dfs 函数接受一个结点，然后对这个结点代表的子树进行求值，返回求值结果。 容易看出，dfs 函数根据被遍历的结点类型不同，执行不同的求值逻辑。 那么我们把这些求值逻辑封装到一个类里面，就得到了一个最简单的 Visitor。 class EvaluationVisitor: def visit(self, node:Node): if isinstance(node, IntNode): return self.visitIntNode(node) if isinstance(node, BinopNode): return self.visitBinopNode(node) def visitIntNode(self, node:IntNode): return node.v def visitBinopNode(self, node:BinopNode): # 不确定子结点的类型，所以只能调用 visit 而非 visitIntNode 或者 visitBinopNode lhs = self.visit(node.lc) rhs = self.visit(node.rc) if node.op == \"+\": return lhs + rhs if node.op == \"-\": return lhs - rhs if node.op == \"*\": return lhs * rhs if node.op == \"/\": return lhs / rhs if node.op == \"%\": return lhs % rhs print(EvaluationVisitor().visit(expr1)) # 21 上面就是 Visitor 的核心思想，实际使用中我们一般会有两点改进 不使用 isinstance 来判断结点类型，而是调用结点自身的一个 accept 函数 把几个 visitXXX 函数抽象到一个接口里，各种具体的 Visitor 来实现这个接口 改进后的 Visitor 如下。 class Node: def accept(self, visitor): pass class IntNode(Node): # ... 同上 def accept(self, visitor): return visitor.visitIntNode(self) class BinopNode(Node): # ... 同上 def accept(self, visitor): return visitor.visitBinopNode(self) class Visitor: # 默认行为是遍历一遍，啥也不做，这样比较方便 def visitIntNode(self, node:IntNode): pass def visitBinopNode(self, node:BinopNode): node.lc.accept(self) node.rc.accept(self) class EvaluationVisitor(Visitor): def visitIntNode(self, node:IntNode): # ... 同上 def visitBinopNode(self, node:BinopNode): lhs = node.lc.accept(self) rhs = node.rc.accept(self) # ... 同上 总结 从上面可以看到，Visitor 模式的要素有 被访问的对象。例如上面的 Node。 Visitor 封装的 visitXXX，表示对上述对象实施的操作。例如 EvaluationVisitor。 每种被访问的对象在自己的定义中都有一个 accept 函数，并且在 Visitor 里面也对应一个 visitXXX 函数。 有状态的 Visitor subexpr = BinopNode('-', IntNode(20), IntNode(13)) expr1 = BinopNode('*', subexpr, IntNode(3)) 显然，表达式求值的过程中，所有子表达式也都会被求值。 如上，求值 expr1 的过程中，subexpr 也也会被求值。 我们想把子表达式的值记录下来，以后直接使用，就不需要对子表达式重新求值了。 为了实现这点，还是使用上面的 EvaluationVisitor，但我们用一个字典 Node -> int 记录求值结果，并且把字典作为 Visitor 的状态。 class EvaluationVisitor2(Visitor): def __init__(self): self.value = {} # Node -> int 每次 EvaluationVisitor2.visitXXX(self, node) 返回的时候，我们都记录一下 self.value[node] = value，其中 value 是返回值。 我们用一个函数修饰器来完成记录的动作，如下 class EvaluationVisitor2(Visitor): def __init__(self): self.value = {} # Node -> int def SaveValue(visit): # decorator def decoratedVisit(self, node): value = visit(self, node) self.value[node] = value return value return decoratedVisit @SaveValue def visitIntNode(self, node:IntNode): return node.v @SaveValue def visitBinopNode(self, node:BinopNode): lhs = node.lc.accept(self) rhs = node.rc.accept(self) if node.op == \"+\": return lhs + rhs if node.op == \"-\": return lhs - rhs if node.op == \"*\": return lhs * rhs if node.op == \"/\": return lhs / rhs if node.op == \"%\": return lhs % rhs subexpr = BinopNode('-', IntNode(20), IntNode(13)) expr1 = BinopNode('*', subexpr, IntNode(3)) visitor = EvaluationVisitor2() expr1.accept(visitor) print(visitor.value[subexpr]) # 7 print(visitor.value[expr1]) # 21 "},"docs/lab2/part0-intro.html":{"url":"docs/lab2/part0-intro.html","title":"摘要","keywords":"","body":"labX 介绍 "},"docs/lab2/summary.html":{"url":"docs/lab2/summary.html","title":"小结","keywords":"","body":"小结 "},"docs/lab3/part0-intro.html":{"url":"docs/lab3/part0-intro.html","title":"摘要","keywords":"","body":"labX 介绍 "},"docs/lab3/summary.html":{"url":"docs/lab3/summary.html","title":"小结","keywords":"","body":"小结 "},"docs/lab4/part0-intro.html":{"url":"docs/lab4/part0-intro.html","title":"摘要","keywords":"","body":"labX 介绍 "},"docs/lab4/summary.html":{"url":"docs/lab4/summary.html","title":"小结","keywords":"","body":"小结 "},"docs/lab5/part0-intro.html":{"url":"docs/lab5/part0-intro.html","title":"摘要","keywords":"","body":"labX 介绍 "},"docs/lab5/stackframe.html":{"url":"docs/lab5/stackframe.html","title":"栈帧","keywords":"","body":"栈帧 《汇编语言》课上已经提到了栈帧的概念 …… …… 只有一个函数 …… IR 的栈帧 …… variables | expr-temps …… 汇编的栈帧 …… ra | fp | 同 IR …… "},"docs/lab5/summary.html":{"url":"docs/lab5/summary.html","title":"小结","keywords":"","body":"小结 "},"docs/lab6/part0-intro.html":{"url":"docs/lab6/part0-intro.html","title":"摘要","keywords":"","body":"labX 介绍 "},"docs/lab6/summary.html":{"url":"docs/lab6/summary.html","title":"小结","keywords":"","body":"小结 "},"docs/lab7/part0-intro.html":{"url":"docs/lab7/part0-intro.html","title":"摘要","keywords":"","body":"labX 介绍 "},"docs/lab7/namer.html":{"url":"docs/lab7/namer.html","title":"名称解析","keywords":"","body":"名称解析 …… 变量名称和变量有区别，int a; { a=2; int a; a=3; } 有两个 a …… …… 以前，每个变量的 use site，根据变量名就能确定唯一变量 …… 引入 block 后，可能出现内外层作用域同名 …… …… 名称解析的概念：唯一确定程序中有哪些变量，以及每个 use site 用的到底是那个变量 …… …… 符号表 …… 作用域栈 …… 如果是 dzy 的代码可以补充以下变量重命名 "},"docs/lab7/summary.html":{"url":"docs/lab7/summary.html","title":"小结","keywords":"","body":"小结 "},"docs/lab8/part0-intro.html":{"url":"docs/lab8/part0-intro.html","title":"摘要","keywords":"","body":"labX 介绍 "},"docs/lab8/summary.html":{"url":"docs/lab8/summary.html","title":"小结","keywords":"","body":"小结 "},"docs/lab9/part0-intro.html":{"url":"docs/lab9/part0-intro.html","title":"摘要","keywords":"","body":"labX 介绍 "},"docs/lab9/cconv.html":{"url":"docs/lab9/cconv.html","title":"调用约定","keywords":"","body":"调用约定 汇编课上也讲过 …… 参数 返回值 CSR callersave …… …… IR 的调用约定：参数从右压栈，返回值栈，………… …… 汇编的调用约定：RISCV 的 …… "},"docs/lab9/prologue.html":{"url":"docs/lab9/prologue.html","title":"函数序言、尾声和调用","keywords":"","body":"函数序言（prologue）、尾声（epilogue）和调用 概念 prologue epilogue 和 calling sequence …… 无论哪个函数 …… 开头和结尾基本固定的一段代码 …… 序言 …… 设立栈帧 …… callee save 尾声 …… 销毁栈帧 …… callee restore …… jr ra 调用不光是一条 call 代码 …… caller save, 传参, call，保存返回值，caller restore "},"docs/lab9/summary.html":{"url":"docs/lab9/summary.html","title":"小结","keywords":"","body":"小结 "},"docs/lab10/part0-intro.html":{"url":"docs/lab10/part0-intro.html","title":"摘要","keywords":"","body":"labX 介绍 "},"docs/lab10/summary.html":{"url":"docs/lab10/summary.html","title":"小结","keywords":"","body":"小结 "},"docs/lab11/part0-intro.html":{"url":"docs/lab11/part0-intro.html","title":"摘要","keywords":"","body":"labX 介绍 "},"docs/lab11/typeck.html":{"url":"docs/lab11/typeck.html","title":"类型检查","keywords":"","body":"类型检查 …… 类型检查是语义检查 …… 不能 int + int …… …… 类型上下文：变量 -> 类型的映射 …… …… 类型规则：参数类型有哪些 -> 返回值类型 …… "},"docs/lab11/summary.html":{"url":"docs/lab11/summary.html","title":"小结","keywords":"","body":"小结 "},"docs/lab12/part0-intro.html":{"url":"docs/lab12/part0-intro.html","title":"摘要","keywords":"","body":"labX 介绍 "},"docs/lab12/summary.html":{"url":"docs/lab12/summary.html","title":"小结","keywords":"","body":"小结 "},"REFERENCE.html":{"url":"REFERENCE.html","title":"参考资料","keywords":"","body":"参考资料 Writing a C Compiler: by Nora Sandler An Incremental Approach to Compiler Construction : by Abdulaziz Ghuloum "}}